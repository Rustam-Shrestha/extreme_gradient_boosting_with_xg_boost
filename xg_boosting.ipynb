{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1260ac-4d7a-4af8-ba0d-384e2bad6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7743f3-554e-4a55-bafd-3d9677a7d8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21944/4072909886.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  churn_data['TotalCharges'].fillna(churn_data['TotalCharges'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the dataset (make sure the CSV is in your working directory)\n",
    "churn_data = pd.read_csv('Telco-Customer-Churn.csv')\n",
    "\n",
    "# Step 2: Drop unnecessary column (customerID is not useful for prediction)\n",
    "churn_data = churn_data.drop('customerID', axis=1)\n",
    "\n",
    "# Step 3: Convert TotalCharges to numeric (it's stored as string; some values are blank)\n",
    "churn_data['TotalCharges'] = pd.to_numeric(churn_data['TotalCharges'], errors='coerce')\n",
    "# Fill NaN in TotalCharges (only 11 rows) with median\n",
    "churn_data['TotalCharges'].fillna(churn_data['TotalCharges'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d2f385-9f2d-4890-8dd6-f98d08df8723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustamshrestha/jupyterenv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [01:14:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784244\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in churn_data.columns:\n",
    "    if churn_data[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        churn_data[column] = le.fit_transform(churn_data[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Now all columns are numeric\n",
    "X = churn_data.iloc[:, :-1]  # All features except last column\n",
    "y = churn_data.iloc[:, -1]   # Last column is 'Churn' (0 = No, 1 = Yes)\n",
    "\n",
    "# Step 5: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "# Step 6: Train XGBoost classifier\n",
    "xg_cl = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,  # Increased for better performance\n",
    "    seed=123,\n",
    "    use_label_encoder=False,  # Suppress warning\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Predict and evaluate\n",
    "preds = xg_cl.predict(X_test)\n",
    "accuracy = float(np.sum(preds == y_test)) / y_test.shape[0]\n",
    "print(\"Accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7487f10-46f3-44ab-9e02-3a0cee55db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the DecisionTreeClassifier with max_depth=4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dt_clf_4.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = float(np.sum(y_pred_4 == y_test)) / y_test.shape[0]\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create the DMatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\": \"binary:logistic\", \"max_depth\": 3}\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, \n",
    "                    metrics=\"error\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {((1 - cv_results['test-error-mean']).iloc[-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba514a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create the DMatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\": \"binary:logistic\", \"max_depth\": 3}\n",
    "\n",
    "# Perform 3-fold cross-validation with AUC metric\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, \n",
    "                    metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print(f\"AUC: {(cv_results['test-auc-mean']).iloc[-1]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Generate synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=4, noise=0.1, random_state=123)\n",
    "\n",
    "# Split the data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\"objective\": \"reg:squarederror\", \"max_depth\": 3, \"eta\": 0.1}\n",
    "\n",
    "# Train the model\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=10)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Compute RMSE and MAE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
